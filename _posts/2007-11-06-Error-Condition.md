---
layout: post
title: "Error Condition"
categories: [Wire Service]
---
<img title="Second Life Self Portrait, Oct 2007" src="http://www.botzilla.com/blog/pix2007/ArtIntelligence.jpg" width="807" height="483" border="0" />

I've been listening to session recordings from the recent <a href="http://www.singinst.org/summit2007/">Singularity Summit.</a> One of the speakers, <a href=http://www.singinst.org/summit2007/speakers/norvig/">Peter Norvig</a> from Google (just a few blocks from the Mountain View coffee shop where I'm now typing this) addressed the speculative concern that Google's vast array of computer systems might spontaneously combust into some sort of consciousness, <i>a la</i> movies like <cite>The Forbin Project</cite> or <cite>Ghost in the Shell.</cite>

To my surprise, they have already spent some billable time on this, thinking about what to monitor: unexplained and unattributed traffic between nodes, across disks, and so forth. In fact they seem to be ready to shut it down at any time. Which implies that to Google, which is itself an entity that's already behaving according to its own logic as a rational economic being: intelligence, in a computer, is an error condition.


